# Contents

<!-- TOC start (generated with https://github.com/derlin/bitdowntoc) -->
- [中国AI创投](#ai)
- [GTC摘要](#gtc)
- [Taco-LLM，腾讯云](#taco-llm)
- [自动驾驶，理想汽车](#)
- [Acknowledgements](#acknowledgements)

<!-- TOC end -->

<!-- TOC --><a name="ai"></a>
# 中国AI创投
- 七维科技CEO殷元江，用AI驱动3D内容生成工具。
  - 分镜故事板生成和场景生成，应用是电影视频漫画广告生成，他们已经有成熟的成果、客户和应用，前景很大。演讲水平，技术水平和商业价值三者最高。
- 必优科技CEO周泽安，内容呈现与表达的文档智能体服务。
  - 输入文档，导出关键信息，例如做PPT，我感觉虽然有用途但好像白开水，很普通。
- zilliz合伙人栾小凡，GPU加持的向量数据库Milvus赋能大规模RAG模型应用。
  - 向量数据库Retrieval Augment Generation，感觉还像理工科毕业答辩而不像商业路演，但技术栈是很有工业价值的，一个比较科研导向的报告。
- 碳硅智慧CEO邓亚峰，生命科学+AI大模型设计新颖的分子结构。
  - 药物发现 = AI建模+自动化试验+专家联合驱动。
  - 专业团队、原创顶级论文、自研算法、商业化平台开放全行业使用。
- 三维家CTO曹健，家居创新。
  - 云建模、云渲染、3D矢量AI，自动生成装修设计仿真模拟。
  - 中国建材家居市场庞大，虽然是细分行业，却有几个亿的销售体量。
  - 行业痛点是数据不同步，从设计、生产到加工要端到端打通买家和厂商，高效生产加工内容，减少生产力重复。
  - 多模态搜索引擎、图像识别的扩展业务：不局限于家具，也包括生活中各类物品在家里的展示，面相通用行业。
- 留形科技CTO徐威，3D建模。
- 使用NVIDIA的初创公司的demo：留形科技，生成式AI。途深生物，医疗健康。必优科技，生成式AI。栩峰科技，生成式AI。摩泛科技，元宇宙。未来速度，生成式AI。碳硅智慧，医疗健康。壹凡物联，元宇宙。IHS智触，医疗健康。七维科技，生成式AI。
- 中国投资人在AI赛道的投资
  - 明势资本的夏令，青岚资本的康毅，宽带资本的刘唯。
  - 理解最深入的我觉得是明势资本的夏令。夏令关心未来十年千万GPU规模算力集群的数据 计算 存储 能源的挑战。三人认为，AI的商业运用是早期的，不及AI大模型的价值更高。24年投资主要看团队迭代速度。刘唯关注多模态方向的应用，to B投资还是集中在赋能，比如安全。

<!-- TOC --><a name="gtc"></a>
# GTC摘要

- Transforming AI，黄仁勋与Transformer论文作者聊天
  - 加速计算，accelerate 1% of code that represents 99% of runtime
  - Transformer论文作者几乎全员创业。
  - Illia Polosukhin, cofounder of NEAR Protocol，创业GPT+blockchain，AI+crypto，耳目一新。
    - 让人们协同工作，以便生成更多数据。We need the new basic primitive, which is programmable money. 可编程的货币可以在大规模上协调人们的行为，我们可以利用这些工具未来生成更多数据。目前我们对创作者的奖励方式存在问题，要为人们提供一种全新的方式来贡献数据, and then you’ll build a whole new positive feedback system。
    - 讨论：programmable money代表了更好的经济激励系统，以后硅基生物的智能足以产生自发的经济效应，crypto的价值会放大更多，因为场景更加native，相辅相生
  - Train models in a different way, not just gradient descent?
- 李飞飞演讲，AI exciting future有一半的广阔场景都是生物医疗药物发现。
- GenAI的下一步，OpenAI COO Brad Lightcap，没啥新意。
- 斯坦福Percy Liang与英伟达Jim Fan聊Foundation Models（FOMO）的未来
  - A field cannot look forward without looking at its past.
  - Foundation Model意思是model trained in self supervised way on a lot of data, and that is a foundation for building a lot of models.
  - Scaling law, foreground and essential.
  - Percy提出一个富有想象力的思考：Agent Architecture / Emerging Social Behaviors。简单说就是用智能agent建造西部世界，缸中之脑的社会模拟器：How can AI generate agent behavior? Simulate a city where people are interacting, each agent powered by language model? （演化生物学的一个简单模型Conway's Game of Life，赋予Cellular智能后，会进行怎样的Automaton？How to build agent architecture where agents have realistic behavior? You have to remember history as agents behavior depends on the past, also have to abstract everything happen in the past and make generalizations. You can plan but you don't want to stick to the plan, you can re-plan. 社会学观察或乌托邦试验，如黑猩猩的政治、Universe 25。）
- 英伟达
  - NeMo框架，帮助企业定制大模型的颠覆式工具。
  - 无限可扩展的高性能AI网络。InfiniBand用数字孪生技术构建AI算力中心。在大模型性能至上时代，赢了网络就赢了算力。
  - 大模型定制芯片设计ChipNeMo，英伟达刘鸣杰
  - 数据中心架构要像计算机一样设计，有控制单元、存储单元、用网络连接。两个方向：
    - AI工厂，超大数据中心运行有限个AI模型，需要最优的网络保证极致的性能，租户隔离不是考虑的关键。
    - 多租户多个不同AI模型的高性能高安全可靠的网络，考虑租户隔离。
  - 量子加速超算，Quantum Cloud, Cuda-Q Academic
- Kanjun Qiu聊天，AI agents that reason at scale
  - Delegation is hard, as a paradigm for agents.
- 企业创新聊天，Salesforce CEO, MasterCard EVP, Intuit CTO, Adobe CIO
- 蚂蚁AI infra负责人Ke Zhang，四个工程实践
  - 智能训练服务DLRover，大规模分布式训练，解耦模型定义，用户只需关注本专业的项目研发本身，也提供用户定制化模型的能力。它的目标是自动并行，自动资源配置，提高长期训练稳定性。本质是提高人、资源、性能的效率。
![image](https://github.com/user-attachments/assets/bf8a9c38-1b61-4d00-afa3-af7cc0c5fbf9)
  - 分布式推理
  - 训练推理显存和传输优化GLake
  - 模型优化器三部曲：无损压缩，提升泛化WSAM，加速收敛AGD
- 百度营销，AI Native
  - 模型，文心大模型。
  - 框架，PaddleBox和PGLBox，大离散模型GPU训练。
  - 芯片，昆仑芯。
  - 应用：广告拍卖端到端效率最优，营销视频AI生成。
- 美团基础研发平台李庆源，PyTorch量化工具MTPQ (OdysseyLLM)
- 吉利汽车陈勇
  - 智能座舱大模型在上车听音乐的高频场景的应用：音乐不仅可以听，也可以被看见，因此构建音乐大模型。根据旋律或歌词，生成音乐背后的意境。在听音乐时享受沉浸式的视听体验。
  - 吉利星睿智算中心，车企首个云数智一体化云计算中心，总算力中国车企第一。

<!-- TOC --><a name="taco-llm"></a>
# Taco-LLM，腾讯云

突破自回归限制，大模型倍速推理引擎Taco-LLM，腾讯云异构计算研发负责人叶帆[Doc](https://static.rainfocus.com/nvidia/gtcs24/sess/1705558318222001VXo1/FinalPresPDF/SE63221%20-%20TACO-LLM%EF%BC%9A%E7%AA%81%E7%A0%B4%E8%87%AA%E5%9B%9E%E5%BD%92%E9%99%90%E5%88%B6%EF%BC%8C%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E5%BA%8F%E5%88%97%E7%BB%B4%E5%B9%B6%E8%A1%8C%E6%8E%A8%E7%90%86%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%88_1709742318805001WDYS.pdf)

- 大模型推理瓶颈是：根据当前token序列预测下一个token，性能被内存带宽限制Auto-regressive decoding process，每次解码一个token却需要加载模型全部权重，因此很浪费算力。
- 要提高计算缓存比，三个思路
![image](https://github.com/user-attachments/assets/381cb8cb-87fd-4be8-b32b-53e94b56e445)
- 对比上述方案，低精度稀疏方案依赖后期训练，无法精度无损，需要额外校正，不利于业务快速迭代。非自回归类模型对场景有限制，如NAT只适用翻译场景，不适用更通用的生成场景。单步解码多token方案很好，可以精度无损，基于caching的思路也不需要额外训练，适合公有云场景，但原始LLMA只适合单batch优化latency，无法continuous batching，对于大吞吐推理服务很局限。
![image](https://github.com/user-attachments/assets/07edba89-5789-4471-976d-0c6ac093013f)
![image](https://github.com/user-attachments/assets/2df398c3-80c6-4fe9-811b-092c19835cd7)
- Lookahead Cache很像向量数据库思想，但很轻量，倾向于输出历史答案，用树结构大幅提高命中率
- Turbo attention是优化的关键
![image](https://github.com/user-attachments/assets/1dfffb70-9524-4065-8a77-132b437b6643)
![image](https://github.com/user-attachments/assets/4d889675-c588-4ffd-8d8f-b9f80b9f91da)

<!-- TOC --><a name=""></a>
# 自动驾驶，理想汽车

理想汽车贾鹏、陈伟。

- 自动驾驶三个层级：L2 Rule-driven, 2D / Mono 3D; L3 Data-driven, End2End / BEV; L4 Knowledge-driven, VLM/WorldModel. 数据驱动、端到端的L3的瓶颈是，尚不够达到用户完全无干预的、未知场景的L4，因此需要知识驱动、世界理解。
- 理想汽车的算法框架分两个部分，快慢系统
  - 快：直觉系统（根据场景L3端到端感知模型，做出判断）
  - 慢：推理认知系统（L4）
    - 车端 = 世界基础知识+短期知识更新快速迭代。模型：Drive-VLM
    - 云端 = 类似Sora生成式世界模型，来训练整体的车端系统。和Sora的不同是，通过静态重建，让静态动态一起生成，从而保证静态更符合物理规律。论文：Street Gaussians. 之后可以加入新的layer，生成无数场景。
- 数据闭环
  - Corner case挖掘不再是手写规则，而是加入自动驾驶先验知识，训练多模态CLIP，把场景用文字表述出来，快速找到场景。论文：BEV-CLIP: Multimodal Data Retrieval。
![image](https://github.com/user-attachments/assets/32df8a12-6f5d-4892-9e56-ce94e7fc103a)


- 智能空间人机交互
  - 3D人机交互：机器主动适应人。
  - 理想汽车的MindGPT在中文大模型评测排名第一，架构和框架性能极高。

![image](https://github.com/user-attachments/assets/aa925f0f-3f31-405f-9c3a-0c14000d4f11)

![image](https://github.com/user-attachments/assets/95724bff-e0d9-4ab3-9619-74121297cafe)

<!-- TOC --><a name="acknowledgements"></a>
# Acknowledgements

[GTC 2024 - Top Talks](https://www.nvidia.com/en-us/on-demand/playlist/playList-87118008-d10b-42f9-8c57-a50bbf006662/)
















