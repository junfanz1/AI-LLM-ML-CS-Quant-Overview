# Contents



- Ollama 是一个全新的本地可运行的大模型框架，可以本地运行的 “ChatGPT”。这节课我们还会用到 GPT-SoVITS。这是一个 TTS（Text-to-Speech，文本转语音）‌大模型，也可以在本地运行。你可能也都听说过多模态这个词，GPT-SoVITS 就是一个语音类的多模态模型。咱们这节课的任务，就是结合 Ollama 的文本能力和 GPT-SoVITS 的语音能力，开发一个可以本地运行的实时语音聊天助手，实现一个类似 ChatGPT 的语音助手。
Ollama 是一套构建和运行大模型的开发框架，它采用的模型量化技术进一步降低了大模型对显存的需求。
- 我们用 Ollama 的 Python 接口来定制自己的大模型。这里面有一个 Modelfile，它是 Ollama 大模型的配置文件，你可以修改各种配置，然后运行接口程序。比如我就自己配置了一个基于 Llama2 的大模型，设置了温度，token 数量和系统提示词。可以使用 Hugging Face 的 transformers 库结合上述数据进行微调, 这样就可以让微调后的大模型学习到小助理日常的对话方式和常见的知识问答。把微调完成后生成新的模型命名为 fine_tuned_llama。在此基础上修改 Python 代码里的模型名称，就可以实现小助理专用模型的调用了。
- 多模态模型和语言模型一样本质就是一个序列化模型。因此多模态只是语言大模型的扩展。
- TTS 大模型：要实现一个语音小助手，最核心的能力当然是语音能力，那语音能力如何跟 Ollama 大模型文本能力对接呢？这里就要用到 TTS 技术。TTS 是 Text-to-Speech 的缩写，指的是文本转语音技术。通过 TTS，用户可以输入文字，让计算机生成自然语音，从而实现语音提示、有声书、语音助手之类的功能。GPT-SoVITS 就是一个可以实现语音克隆的 TTS 大模型，最大的特点是只需要 5s 左右的语音输入样本，就可以实现语音克隆，之后还可以用我们训练好的模型实现 TTS 文本转语音操作，音色、音调的还原度也很高。
- 微调：将一部分专业私有数据加入大模型，整个大模型就具备了某项专业能力。如果你想完全避免私有数据的幻觉问题，可以用向量数据库结合大模型开发。向量数据库 VS 微调在工程实践经验看来，向量数据库往往比微调效果还好。
- 专有模型开发：你如果对全能数据库本身不满意，还可以基于开源大模型二次开发，也就是我们说的专有模型开发，例如专门实现代码开发能力的大模型。这个基于开源大模型的二次开发，又分为两种情况，偏向行业数据的行业大模型开发，以及偏向大模型能力扩展的大模型插件开发。专有模型相当于全能数据库的二次开发，以及全能数据库自定义函数的开发。最终的应用往往需要在专有 LLM 或公有 LLM 基础上结合私有数据微调，同时结合已有的应用接口整合出一个可靠的 AI 应用，避免大模型那些出错的“幻觉”，留下我们需要的创造性。



# Acknowledgements

- [AI大模型项目落地实战](https://time.geekbang.org/column/article/801454)
