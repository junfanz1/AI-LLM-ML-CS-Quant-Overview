DeepSeek Large Model High-Performance Core Technology and Multimodal Fusion Development, by Xiaohua Wang, 2025

<img src="https://github.com/user-attachments/assets/1c3c59ff-4b22-4163-a12b-cfc027950602" width="32%" height="32%">

## 3. 注意力

- 分组查询注意力Group Query Attention (GQA)：共享键和值矩阵，减少显存占用，提高推理速度，适合长序列大模型。
- 多头潜在注意力MLA：低秩压缩（高维矩阵->多个低维矩阵乘积），降低KV cache需求，高效推理且高质量输出。



















