
Unveiling Large Model, by Liang Wen, 2025

<img src="https://github.com/user-attachments/assets/65fd0bf1-dde7-4282-a7aa-fd413812c686" width="34%" height="34%">

# Contents

<!-- TOC start (generated with https://github.com/derlin/bitdowntoc) -->

- [1. 压缩即智能](#1-)
- [5. Llama](#5-llama)
- [8. 大模型训练优化](#8-)
- [10. AIGC](#10-aigc)
- [11. 推荐系统](#11-)

<!-- TOC end -->

（不全面的笔记）

<!-- TOC --><a name="1-"></a>
## 1. 压缩即智能

GPT训练过程本质是对整个数据集的无损压缩。规模越大越智能，因为大模型的低损失实现更高压缩率。

<!-- TOC --><a name="5-llama"></a>
## 5. Llama

- Pre-normalization：用RMSNorm作为归一化函数，每个Transformer子层之前对输入归一化
- SwiGLU：SWISH+GLU，优化Transformer前馈网络
- 旋转位置编码RoPE：提高模型外推能力，将相对位置信息集成到自注意力中的绝对位置编码方式
- AdamW优化器：将weight decay从梯度更新中分离出来，提高优化效果。用cosine learning rate decay根据余弦曲线动态调整学习率，避免学习率在切换时产生动荡。
- RLHF：通过rejection sampling和PPO迭代优化。
  - 强化学习微调预训练模型：近端策略优化Proximate Policy Optimization (PPO)，用奖励模型评估回答的分数。目标函数 = 强化学习输出不要偏离有监督微调太多 + 保证微调效果的同时让语言模型在通用能力上效果不变差。
  - Llama 2奖励函数 = 有用性 + 安全性。将人类偏好数据转换为二元排序标签格式（选择和拒绝），用binary ranking loss优化奖励模型；加入边际项，根据差异大小的回答对分配边际值，提高在区分度高的样本上的准确度。
- 预训练数据：对较高准确性的数据up-sampling，增加模型知识和减少幻觉。
- 分组查询注意力Grouped-query Attention (GQA)：提高大模型推理可扩展性。

<!-- TOC --><a name="8-"></a>
## 8. 大模型训练优化

- 稀疏Transformer：降低显存消耗、加速训练。将全连接自注意力分解为多个稀疏自注意力，时间复杂度O(n^2) -> O(n√n)
  - 分解注意力Factorized attention有两种
    - stride attention只关注序列中一定步长间隔的位置，由两种连接模式组成：行和列 注意力模式。
    - fixed attention只关注序列中固定几个位置，由两种连接模式组成：行和列（又称sliding window）注意力模式。
  - 稀疏Transformer只想让一些预先设定的像素点参与自注意力计算，引入connectivity pattern连接模式减少时间复杂度。
  - 融合多个注意力核，三种：每个残差块用一种注意力核，每个注意力头计算所有注意力核然后结果合并，每组注意力头用一种注意力核然后结果拼接。
- 旋转位置编码RoPE：能处理没见过的长序列
  - 对每个词嵌入，计算查询向量和键向量，然后计算每个词位置对应的旋转位置编码，然后两两一组用旋转变换调整每个词位置的查询向量和键向量的元素，最后计算查询向量和键向量的内积，得到自注意力的结果。
  - 传统位置编码是加性的（只表示绝对位置，不表示相对位置），旋转位置编码是乘性的（与线性注意力机制兼容，降低时间复杂度，还能增强对位置信息的感知），可以带来远程衰减性，可以通过旋转矩阵实现位置编码的外推，生成超预期训练长度的位置编码，提高泛化能力和鲁棒性。
- 混合精度
  - 权重备份weight backup，解决四舍五入误差，用FP16的梯度、权重，复制一份FP32的权重参数，在训练时更新，适用于神经网络学习率*梯度很小时FP16相加的误差。训练时显存分为动态显存和静态显存，额外复制一份权重只增加静态显存，而动态显存FP16存储，仍然可以比FP32训练节省一半显存占用。
  - 精度累加precision accumulated，用FP16提高矩阵乘法效率，FP32保证加法精度
  - 损失缩放loss scaling，避免梯度值太小导致数据下溢，可以放大损失值，把FP32参数乘以2^K因子系数到FP16数据范围内，再由链式求导反向传播梯度。
- 并行训练
  - 数据并行：一个模型权重复制到多个设备，然后把数据集切分，每个设备处理一份数据并计算梯度，然后把梯度聚合更新模型权重。但显存占用大，通信开销大，适用于模型小而数据大的情况。
  - 张量并行：模型某些张量（权重矩阵、激活值向量）沿着特定维度切分，分配到不同设备。可以训练超大模型，不受单个设备显存限制；但需要修改模型结构，适应张量切分方式，要额外通信来同步张量。
  - 流水线并行：模型按阶段切分，分到不同设备按顺序运行。可以充分利用每个设备计算能力，减少空闲时间，但需要对模型切分，保证负载均衡，需要额外通信传输中间结果。

<!-- TOC --><a name="10-aigc"></a>
## 10. AIGC

- 去噪扩散概率模型denoising diffusion probabilistic model (DDPM)
  - 前向扩散过程，反向去噪过程。U-Net（下采样编码+上采样解码器）是噪声估计函数，在每个ResNet加入注意力机制（输入可以是文本向量，训练过程是先用CLIP生成文本向量，然后U-Net训练）。
- 文生图
  - 去噪扩散概率模型先用文本编码器把文字转换为文本向量（基于CLIP模型），再讲文本向量和随机噪声向量、时间步长向量一起输入去噪扩散概率模型，用多个U-Net叠加生成图像向量，再用图像编码器生成最终图像。
  - CLIP：多模态学习模型，基于图像和文字的数据集训练，目标是让图像和文字有最大相似度，用余弦相似度衡量图像与文字相似度。
- Stable Diffusion
  - 去噪概率模型的缺点：反向去噪过程需要把完整图像输入U-Net，太慢。Stable Diffusion输入文字经过CLIP文本编辑器转换文本向量，然后和原始图像（初始化为随机搞死噪声）一起输入去噪模块（文本条件U-Net模型），输出清晰图像。
  - 前向扩散过程发生在latent space而非原始图像，也就是对图像做了压缩，因此很快。

<!-- TOC --><a name="11-"></a>
## 11. 推荐系统

- 两阶段：先用大模型提取文本特征，再用推荐系统的神经网络进行预测
- 端到端：直接大模型完成推荐
- 预训练+两阶段/端到端：先用推荐系统数据对大模型预训练，然后两阶段/端到端推荐，在此基础上可以再加入ID特征推荐













